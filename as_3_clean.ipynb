{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e69a06b",
   "metadata": {
    "id": "9e69a06b"
   },
   "source": [
    "# Multilabel Classification — DT · LSTM · BERT\n",
    "One dataset (GoEmotions) for all models; PCA visualization; Confusion Matrices; summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07496b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "bc140371b8664e8b86ff6492db2e91be",
      "2e506ffa4fe84472ace128a8b9d0e683",
      "eca3865593104f8096a3e58435e8ea9e",
      "a44edac541454922924efa5517399fd3",
      "4cad3c028bbb4d929b7e8536dda43008",
      "c11e809767004168ab6869d022e419f8",
      "0e9b838343a34a709353c5fd3cc62c0c",
      "795489f3b9694a7589d6980ae63357d0",
      "4d595812e53c417faf690804e60d2245",
      "0ddb565516544db8aeceb8874d030295",
      "8935ef8c9fc14c21b91864e28af79616",
      "8dd003a86bd74109831ece1787bacc97",
      "6801eab501c14e16bcbb25788213181f",
      "3a6820e11ead4e06aed30595adb2a8da",
      "38f0fe0f2dc84d959c968dbb9c5eb198",
      "64923282fa254776862f4c102b3626b9",
      "43777aa528aa4bf081feff7729924c31",
      "2012abe9707b4cdeae4e9ccf41f5e6a0",
      "f9c424bc11734b90b77a32fab7d0b58d",
      "e983574a25854258991ce6556fb327e7",
      "8550924968a941a1ba3880b1fc747ba1",
      "b1903ae66f274f868fab4bebc78fc0c9",
      "2cc6d2d8416d41c5a5de123f99e4e2c7",
      "6a76b84370ea42299c0e9821732ddabe",
      "3e946ce496f94f9c9a987274a6e12e02",
      "3c4d148fb03b4da5be03dfde38038322",
      "3806b366430f497e9fdd68c26c142db5",
      "ad1f26c470ff420589306f1831419ea8",
      "9e3a0b73b84b4260aeec1018f7f66dd0",
      "32f988d723124a72a79e4f3403aca87d",
      "adeaf060e156454c9154b0c943995a27",
      "e17242caa5804542a796529f55e03446",
      "710e3368babb4ac3b9309f0404b3faf4",
      "daa50978fc8041b2bcd6b40b65233227",
      "090f4c025ce04c2898b3e674b41b7c7f",
      "5c12b51f75f14bff9bea5dbc7d70ce68",
      "5009340e656d42ebaa9f78e382ad600e",
      "582b8eb1efbc435d89451980c77bb06c",
      "927c3d37acfb45db937f2180dbc47b35",
      "551ab28868ad4f20b93cddb5c1f6c3e2",
      "4b7ad338fcd943c090e629b7976dddee",
      "211c2babce8b48f78648f9d7595128ec",
      "664ae03b621e47c3924ab45e51df2c5a",
      "34e80b10597f4424ad6a826452ed1e2d",
      "7de4c1789f4742799460e3e0f276e42c",
      "abb0ef373ff64bc38f967295b33d9b70",
      "c10786638a2a4e23957e526fecba8ad6",
      "78aad77d81c34a198e9bf23d329bda33",
      "6ee355216ae84745bf5c6eded3231c8d",
      "69e0bcccd71447358eca81c8436cb17d",
      "ee9aade205d94726a40f6b5a96ccc3bf",
      "5b973c8d8e5e4bcc8890719b3aba8de2",
      "0c2ea1769918415796fe80c9017dba03",
      "cd2c5fb8e92e4e2385a775b68f180d6b",
      "a41579806a6f43c4906df3b2cc5c3fe2",
      "e2dc1a6e102643b3a8d48629840cd1ff",
      "ae5d1bd328c54a05a06e501096f4256a",
      "b3f7bf329ff64e20b5496df84ac4c7e9",
      "4674936757d943f49996b4dce166100e",
      "77cbaec6a5274438ba5f8bd3152a468b",
      "8fd7acec9ffa4ce48c7bc5857004369b",
      "ae69e9b5a21247eab13cc7b96b3e2473",
      "ec862200acbd4366be86062194cab677",
      "a5a22aa63e34462ea6bd5180c66d8a00",
      "4294d06248854ad49ba06824fe862ae1",
      "7227df6f41cf4cbebcfb3aa3a50e8f61",
      "fed07877a4b14569aa148a8c52872edf",
      "76ebd2f02e8d4b3e94dc92459db077df",
      "9eba8a14b2eb4797be223a395b64659c",
      "d1c8012d88354b788abce6df1b7bdb65",
      "572c450ec66449a88d7100a26b3331dc",
      "9eda78b114f54583a28449e7b27222e3",
      "ac8cb2e943484362af1fb4a9335a3532",
      "0c20719e001048e59ce3829709a41b3b",
      "3e53205d78e545c68868371599dfa7e4",
      "a97f54951b714294ade7bddf38c39b80",
      "f01e35d9622b4864abbf207bcd16e74e"
     ]
    },
    "id": "b07496b4",
    "outputId": "61a9d71f-6f6f-4c64-e60a-3471d31cf561"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip -q install datasets transformers accelerate evaluate torch tensorflow==2.16.1 scikit-learn pandas matplotlib --upgrade\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "ds = load_dataset(\"go_emotions\")\n",
    "label_names = ds[\"train\"].features[\"labels\"].feature.names\n",
    "NUM_LABELS = len(label_names)\n",
    "\n",
    "Xtr_txt = ds[\"train\"][\"text\"]\n",
    "Ytr_idx = ds[\"train\"][\"labels\"]\n",
    "Xte_txt = ds[\"test\"][\"text\"]\n",
    "Yte_idx = ds[\"test\"][\"labels\"]\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=list(range(NUM_LABELS)))\n",
    "Y_train = mlb.fit_transform(Ytr_idx)\n",
    "Y_test  = mlb.transform(Yte_idx)\n",
    "\n",
    "print(f\"Labels: {NUM_LABELS} — {label_names[:5]} ...\")\n",
    "print(\"Train/Test:\", len(Xtr_txt), len(Xte_txt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15269711",
   "metadata": {
    "id": "15269711"
   },
   "source": [
    "## 1) Decision Tree (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45fc38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb45fc38",
    "outputId": "50d2fa87-e010-498f-fb27-53105c4d014c"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1,2), min_df=2)\n",
    "Xtr = tfidf.fit_transform(Xtr_txt)\n",
    "Xte = tfidf.transform(Xte_txt)\n",
    "\n",
    "svd_300 = TruncatedSVD(n_components=300, random_state=42)\n",
    "Xtr300 = svd_300.fit_transform(Xtr)\n",
    "Xte300 = svd_300.transform(Xte)\n",
    "\n",
    "dt = OneVsRestClassifier(DecisionTreeClassifier(random_state=42, min_samples_leaf=2))\n",
    "t0 = time.time()\n",
    "dt.fit(Xtr300, Y_train)\n",
    "fit_dt = time.time() - t0\n",
    "\n",
    "t1 = time.time()\n",
    "Yp_dt = dt.predict(Xte300)\n",
    "pred_dt = time.time() - t1\n",
    "\n",
    "f1_micro_dt = f1_score(Y_test, Yp_dt, average=\"micro\", zero_division=0)\n",
    "f1_macro_dt = f1_score(Y_test, Yp_dt, average=\"macro\", zero_division=0)\n",
    "print(f\"DT: fit {fit_dt:.1f}s pred {pred_dt:.1f}s F1_micro={f1_micro_dt:.3f} F1_macro={f1_macro_dt:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18324986",
   "metadata": {
    "id": "18324986"
   },
   "source": [
    "## 2) LSTM (Keras, BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c3538",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a6c3538",
    "outputId": "9844d7f7-5407-4230-b037-6206c7934258"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "max_words = 40000\n",
    "max_len = 128\n",
    "\n",
    "tok = Tokenizer(num_words=max_words, oov_token=\"<unk>\")\n",
    "tok.fit_on_texts(Xtr_txt)\n",
    "Xtr_seq = pad_sequences(tok.texts_to_sequences(Xtr_txt), maxlen=max_len)\n",
    "Xte_seq = pad_sequences(tok.texts_to_sequences(Xte_txt),  maxlen=max_len)\n",
    "\n",
    "num_labels = Y_train.shape[1]\n",
    "model_lstm = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(num_labels, activation=\"sigmoid\")\n",
    "])\n",
    "model_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "t0 = time.time()\n",
    "model_lstm.fit(Xtr_seq, Y_train, epochs=2, batch_size=128, validation_split=0.1, verbose=1)\n",
    "fit_lstm = time.time() - t0\n",
    "\n",
    "t1 = time.time()\n",
    "probs = model_lstm.predict(Xte_seq, verbose=0)\n",
    "Yp_lstm = (probs>0.5).astype(int)\n",
    "pred_lstm = time.time() - t1\n",
    "\n",
    "f1_micro_lstm = f1_score(Y_test, Yp_lstm, average=\"micro\", zero_division=0)\n",
    "f1_macro_lstm = f1_score(Y_test, Yp_lstm, average=\"macro\", zero_division=0)\n",
    "print(f\"LSTM: fit {fit_lstm:.1f}s pred {pred_lstm:.1f}s F1_micro={f1_micro_lstm:.3f} F1_macro={f1_macro_lstm:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21dfcb",
   "metadata": {
    "id": "de21dfcb"
   },
   "source": [
    "## 3) BERT (bert-base-uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928186d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328,
     "referenced_widgets": [
      "f484d22550b347bd926cfe5f672b2f0f",
      "a175cb226a214718880818701a6a35d2",
      "2e7cfcf698794c91acfa57410895aa3e",
      "694df2d7e0ab44f7afb48de260b2190a",
      "8480ddd4662d4fe4b19ad4cb99c56407",
      "7dd7315807194f2db0d058461a2806ee",
      "e2185b2aa35241c9b3a3301a78c226ec",
      "fe598be4c3ec42c3b4469bb1cefb3d05",
      "8dd7add1fba745e6bd11f825e45ede90",
      "e83ad06a5617461d9d0f7d93bc11f30a",
      "04dae5415a984695ae6e193555cc3366",
      "35a4a487353e4a389b98ec43724ce087",
      "2d12c7a77013477a836415d48454f07a",
      "3a6489ee8cd6458495f0b6507aa1c50b",
      "0d1dafcd30e14688b796997136d13031",
      "0c371bfccf0b48918d2d68104f53e9ff",
      "26e08edc71b144a1a53786e29f12f947",
      "23fedd1e846d4910b726d56b9716b7a2",
      "9472726eeaef4170ad68888df6be2ff0",
      "d20ee6ee17e04a74a59d295a11470b46",
      "f432a5ce3554483b8eaf819d7d7de3fb",
      "7088efd390fa4d39a0e2d20e70d43906",
      "40e98c4641fd4a7c899d848ac04417c1",
      "2b7381b68adf4b61bc70f63941e8cf26",
      "a033a863159c45a99e017a4fe07f48e3",
      "e1354fff67554988a1ab03dab5adef11",
      "084f099243db460ba17ec1c7de5e7d9a",
      "33834fa5d88a4fb088bbdeffd664c447",
      "51c53722a1a243738dc3c0134a9e16ba",
      "1c60b71627784e2581c80109ae56797a",
      "2a75c717e7264d2a8de46c14e7284559",
      "c5e28d9a7c9b454580e8793fd7c336d2",
      "08c6a8be707e4275ae80172e22751df3",
      "5fc821c57f30485f989576d01a9972b6",
      "df0aa9b939b34e7c91aad31b740a7d78",
      "cd3b5590a6084bc89235d86bf8ddb6e4",
      "febd304465ee44aeb1b443e206d3db19",
      "9830c347553841a3bf1c4417d6936207",
      "f04e3d710538461a80e392fc97d8d830",
      "287a341aa8dc4deda63cd7e527296299",
      "6a14fa06b11d4b618048218c733a8bdc",
      "2f4c7a40ac0b4fed9746249f7010e41e",
      "78006facbbc64e6b9eddb203045b1e19",
      "7fd9fc16af3b4687899d75cd22e56ca8"
     ]
    },
    "id": "f928186d",
    "outputId": "adf892d2-0bca-4955-b064-3834f252e9b4"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, Sequence, Value\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_df = pd.DataFrame({\"text\": Xtr_txt, \"labels\": list(Y_train)})\n",
    "test_df  = pd.DataFrame({\"text\": Xte_txt, \"labels\": list(Y_test)})\n",
    "ds_tr = Dataset.from_pandas(train_df)\n",
    "ds_te = Dataset.from_pandas(test_df)\n",
    "\n",
    "def tokenize(batch):\n",
    "    enc = tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    enc[\"labels\"] = np.asarray(batch[\"labels\"], dtype=np.float32)  # <-- float32\n",
    "    return enc\n",
    "\n",
    "ds_tr = ds_tr.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "ds_te = ds_te.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "ds_tr = ds_tr.cast_column(\"labels\", Sequence(Value(\"float32\")))\n",
    "ds_te = ds_te.cast_column(\"labels\", Sequence(Value(\"float32\")))\n",
    "\n",
    "model_bert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_names), problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    return {\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"precision_micro\": precision_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"recall_micro\": recall_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"bert-goemotions\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_bert,\n",
    "    args=args,\n",
    "    train_dataset=ds_tr,\n",
    "    eval_dataset=ds_te,\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "import time\n",
    "t0 = time.time(); trainer.train(); fit_bert = time.time() - t0\n",
    "t1 = time.time(); eval_res = trainer.evaluate(); pred_bert = time.time() - t1\n",
    "\n",
    "print(\n",
    "    f\"BERT: fit {fit_bert:.1f}s pred {pred_bert:.1f}s \"\n",
    "    f\"F1_micro={eval_res['eval_f1_micro']:.3f} F1_macro={eval_res['eval_f1_macro']:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd1562",
   "metadata": {
    "id": "6ddd1562"
   },
   "source": [
    "## 4) SVD→PCA 2D visualization (TF‑IDF of test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeec3ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "bbeec3ff",
    "outputId": "e12bdafe-c8ff-4062-8104-064aa9b34de8"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "\n",
    "svd_50 = TruncatedSVD(n_components=50, random_state=42)\n",
    "Xvis50 = svd_50.fit_transform(Xte)\n",
    "pca2 = PCA(n_components=2, random_state=42)\n",
    "Xvis2 = pca2.fit_transform(Xvis50)\n",
    "\n",
    "label_counts = Y_test.sum(axis=1)\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(Xvis2[:,0], Xvis2[:,1], c=label_counts, s=6, alpha=0.6)\n",
    "plt.title(\"GoEmotions — 2D (SVD50→PCA2), color=#labels/sample\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.colorbar(label=\"# labels\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27eaff",
   "metadata": {
    "id": "0f27eaff"
   },
   "source": [
    "## 5) Confusion Matrices (top‑10 frequent labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607176bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "607176bd",
    "outputId": "d54209ec-cfc0-4c1b-edaa-f1156fb80c56"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "def plot_cm_single(cm, title=\"\"):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    m = np.array([[tp, fp],\n",
    "                  [fn, tn]], dtype=int)\n",
    "\n",
    "    plt.figure(figsize=(4, 3.6))\n",
    "    plt.imshow(m, aspect=\"auto\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Pred\")\n",
    "    plt.xticks([0,1], [\"1\", \"0\"])\n",
    "    plt.yticks([0,1], [\"1\", \"0\"])\n",
    "\n",
    "    for (i, j), val in np.ndenumerate(m):\n",
    "        plt.text(j, i, str(val), ha=\"center\", va=\"center\", fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_cm_set(name, Y_true, Y_pred, label_names, top_k=10):\n",
    "    freq = Y_true.sum(axis=0)\n",
    "    top_labels = np.argsort(freq)[::-1][:top_k]\n",
    "    mlcm = multilabel_confusion_matrix(Y_true, Y_pred)\n",
    "\n",
    "    print(f\"\\n=== Confusion Matrices — {name} (top-{top_k}) ===\")\n",
    "    for idx in top_labels:\n",
    "        cm = mlcm[idx]\n",
    "        support = int(freq[idx])\n",
    "        title = f\"{label_names[idx]} (idx={idx}, support={support})\"\n",
    "        plot_cm_single(cm, title=title)\n",
    "\n",
    "preds = trainer.predict(ds_te).predictions\n",
    "probs = 1/(1+np.exp(-preds))\n",
    "Yp_bert = (probs > 0.5).astype(int)\n",
    "f1_micro_bert = f1_score(Y_test, Yp_bert, average=\"micro\", zero_division=0)\n",
    "f1_macro_bert = f1_score(Y_test, Yp_bert, average=\"macro\", zero_division=0)\n",
    "precision_micro_bert = precision_score(Y_test, Yp_bert, average=\"micro\", zero_division=0)\n",
    "recall_micro_bert    = recall_score(Y_test, Yp_bert, average=\"micro\", zero_division=0)\n",
    "\n",
    "print(f\"BERT (computed): F1_micro={f1_micro_bert:.3f}  F1_macro={f1_macro_bert:.3f}\")\n",
    "\n",
    "plot_cm_set(\"Decision Tree\", Y_test, Yp_dt, label_names, top_k=10)\n",
    "plot_cm_set(\"LSTM\",          Y_test, Yp_lstm, label_names, top_k=10)\n",
    "plot_cm_set(\"BERT\",          Y_test, Yp_bert, label_names, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2cb2a6",
   "metadata": {
    "id": "8c2cb2a6"
   },
   "source": [
    "## 6) Comparative table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449b5ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "9449b5ad",
    "outputId": "e097dfe3-fc49-46f2-ddf2-85dee29ff9ca"
   },
   "outputs": [],
   "source": [
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"Approach\":\"Classical ML\",\"Method\":\"Decision Tree (OvR)\",\"dataset\":\"GoEmotions\",\n",
    "     \"amount of data\": f\"{len(Xtr_txt)} train / {len(Xte_txt)} test; {len(tfidf.get_feature_names_out())} tfidf feats; {NUM_LABELS} labels\",\n",
    "     \"speed\": f\"{fit_dt:.1f} s\",\"Accuracy (F1_micro)\": f\"{f1_micro_dt:.3f}\"},\n",
    "    {\"Approach\":\"Neural Networks\",\"Method\":\"LSTM (BiLSTM)\",\"dataset\":\"GoEmotions\",\n",
    "     \"amount of data\": f\"{len(Xtr_txt)} train / {len(Xte_txt)} test; {NUM_LABELS} labels\",\n",
    "     \"speed\": f\"{fit_lstm:.1f} s\",\"Accuracy (F1_micro)\": f\"{f1_micro_lstm:.3f}\"},\n",
    "    {\"Approach\":\"Transformers\",\"Method\":\"BERT (bert-base-uncased)\",\"dataset\":\"GoEmotions\",\n",
    "     \"amount of data\": f\"{len(Xtr_txt)} train / {len(Xte_txt)} test; {NUM_LABELS} labels\",\n",
    "     \"speed\": f\"{fit_bert:.1f} s\",\"Accuracy (F1_micro)\": f\"{f1_micro_bert:.3f}\"},\n",
    "])\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}